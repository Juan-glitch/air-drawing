{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNNs are used over point sequence to predict whether the user wanted to have the pencil up or pencil down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "import cv2\n",
    "from os import listdir\n",
    "from contextlib import ExitStack\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.0+cu102\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DrawingsDS(torch.utils.data.Dataset):\n",
    "    def __init__(self, folder=\"../../data/processed_labeled/\"):\n",
    "        self.folder = folder\n",
    "        self.ds = []\n",
    "        self.n = 6\n",
    "        for f in listdir(self.folder):\n",
    "            self.ds.append(self.load_file(f))\n",
    "        \n",
    "        self.compute_mean()\n",
    "        self.compute_std()\n",
    "        \n",
    "        for f in self.ds:\n",
    "            f['input'] = (f['input'] - self.mean)/self.std\n",
    "        \n",
    "    def compute_mean(self):\n",
    "        self.mean = np.zeros(self.n)\n",
    "        tot = 0\n",
    "        self.y_mean = 0\n",
    "        for f in self.ds:\n",
    "            x = f['input']\n",
    "            self.mean += np.sum(x,axis=0)\n",
    "            self.y_mean += np.sum(f['output'])\n",
    "            tot += x.shape[0]\n",
    "        self.mean /= tot\n",
    "        self.y_mean /= tot\n",
    "        \n",
    "        \n",
    "    def compute_std(self):\n",
    "        variance = np.zeros(self.n)\n",
    "        tot = 0\n",
    "        for f in self.ds:\n",
    "            x = f['input'] - self.mean\n",
    "            x = np.square(x)\n",
    "            variance += np.sum(x,axis=0)\n",
    "            tot += x.shape[0]\n",
    "        variance /= tot\n",
    "        self.std = np.sqrt(variance)\n",
    "        \n",
    "    def load_file(self,f):\n",
    "        df = pd.read_csv(self.folder+f,index_col=0)\n",
    "        raw_pos = df[['x','y']].to_numpy().astype(np.int)\n",
    "        raw_inputs = df[['vx','vy','v','ax','ay','a']].to_numpy().astype(np.double).copy()\n",
    "        inputs = df[['vx','vy','v','ax','ay','a']].to_numpy().astype(np.double).copy()\n",
    "        output = df[['label']].to_numpy().astype(np.double)\n",
    "        distance = df[['dist']].to_numpy().astype(np.double)\n",
    "        return {\n",
    "            'raw_pos' : raw_pos,\n",
    "            'raw_input' : raw_inputs,\n",
    "            'input' : inputs,\n",
    "            'output' : output,\n",
    "            'name': f,\n",
    "            'dist': distance\n",
    "        }\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.ds[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.26297980e-01  1.41309001e-01  5.43238416e+00  4.96403502e-05\n",
      "  1.54440421e-02  5.29778293e+00]\n",
      "0.560743728392873\n",
      "[ 7.58949818  6.60065734  8.46724758  9.15636004  7.58639267 10.64546933]\n",
      "(589, 6)\n",
      "(589, 1)\n"
     ]
    }
   ],
   "source": [
    "dataset = DrawingsDS()\n",
    "print(dataset.mean)\n",
    "print(dataset.y_mean)\n",
    "print(dataset.std)\n",
    "print(dataset[0]['input'].shape)\n",
    "print(dataset[0]['output'].shape)\n",
    "train_set, test_set = torch.utils.data.random_split(dataset,(50,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(sample,pred):\n",
    "    sample_output = np.squeeze(pred)\n",
    "    pts = sample['raw_pos'][sample_output == True]\n",
    "\n",
    "    img = np.zeros((720,1280), dtype=np.uint8)\n",
    "    img[pts.T[1],pts.T[0]]=255\n",
    "    img = cv2.flip(img, 1)\n",
    "\n",
    "    cv2.imshow('frame', img)\n",
    "    key = cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnBlock(torch.nn.Module):\n",
    "    def __init__(self,in_features,num_heads,out_features): \n",
    "        super(AttnBlock, self).__init__()\n",
    "        self.attn = torch.nn.MultiheadAttention(\n",
    "            embed_dim = in_features,\n",
    "            num_heads = num_heads,\n",
    "            batch_first = True\n",
    "        )\n",
    "        self.fwd = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_features=in_features,out_features=out_features),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "        self.relu = torch.nn.ReLU()\n",
    "    def forward(self,x):\n",
    "        return self.relu(self.fwd(self.attn(x,x,x)[0]))\n",
    "    \n",
    "class ConvBlock(torch.nn.Module):\n",
    "    def __init__(self,in_features,out_features,kernel_size=9):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv = torch.nn.Conv1d(\n",
    "            in_channels=in_features,\n",
    "            out_channels=out_features,\n",
    "            kernel_size=kernel_size,\n",
    "            padding=kernel_size//2\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        output = torch.transpose(x,1,2)\n",
    "        output = self.conv(output)\n",
    "        output = torch.transpose(output,1,2)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyConvModel(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size=6,\n",
    "        output_size=1,\n",
    "        conv_seq=[16,32,64,128,64,32,16]\n",
    "    ):\n",
    "        super(FullyConvModel, self).__init__()\n",
    "    \n",
    "        layers = [ConvBlock(input_size,conv_seq[0])]\n",
    "        for k in range(len(conv_seq)-1):\n",
    "            layers.append(ConvBlock(conv_seq[k],conv_seq[k+1]))\n",
    "        self.layers = torch.nn.Sequential(*layers)\n",
    "        self.fc1 = torch.nn.Linear(in_features=conv_seq[-1],out_features=conv_seq[-1]//2)\n",
    "        self.fc2 = torch.nn.Linear(in_features=conv_seq[-1]//2,out_features=conv_seq[-1]//2)\n",
    "        self.fc3 = torch.nn.Linear(in_features=conv_seq[-1]//2,out_features=output_size)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        output = self.layers(x)\n",
    "        output = self.fc3(self.relu(self.fc2(self.relu(self.fc1(output)))))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvRecurrentModel(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size=6,\n",
    "        output_size=1,\n",
    "        hidden_size_in=64,\n",
    "        hidden_size_out=32,\n",
    "        num_layers=2,\n",
    "        model=torch.nn.GRU,\n",
    "        dropout=0.2,\n",
    "        bidirectional=True\n",
    "    ):\n",
    "        super(ConvRecurrentModel, self).__init__()\n",
    "        self.rnn = model(\n",
    "            input_size = hidden_size_in,\n",
    "            hidden_size = hidden_size_out,\n",
    "            num_layers = num_layers,\n",
    "            dropout = dropout,\n",
    "            bidirectional = bidirectional\n",
    "        )\n",
    "        self.before = torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(in_channels=input_size,out_channels=hidden_size_in//2,kernel_size=3,padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv1d(in_channels=hidden_size_in//2,out_channels=hidden_size_in//2,kernel_size=3,padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv1d(in_channels=hidden_size_in//2,out_channels=hidden_size_in,kernel_size=3,padding=1)\n",
    "        )\n",
    "        self.after = torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(in_channels=2*hidden_size_out,out_channels=hidden_size_out,kernel_size=3,padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv1d(in_channels=hidden_size_out,out_channels=hidden_size_out,kernel_size=3,padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv1d(in_channels=hidden_size_out,out_channels=hidden_size_out//2,kernel_size=3,padding=1)\n",
    "        )\n",
    "        self.fc = torch.nn.Linear(in_features=hidden_size_out//2,out_features=output_size)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = torch.transpose(x,1,2)\n",
    "        output = self.before(x)\n",
    "        \n",
    "        output = torch.transpose(output,2,1)\n",
    "        output = torch.transpose(output,0,1)\n",
    "        output, _ = self.rnn(output)\n",
    "        output = torch.transpose(output,0,1)\n",
    "        \n",
    "        output = torch.transpose(output,2,1)\n",
    "        output = self.after(output)\n",
    "        \n",
    "        output = torch.transpose(output,2,1)\n",
    "        output = self.fc(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The full model to be exported into ONNX. \n",
    "This model contains input normalization + sigmoid function at the end.\n",
    "\"\"\"\n",
    "class StandaloneModel(torch.nn.Module):\n",
    "    def __init__(self, trained_model, mean, std):\n",
    "        super(StandaloneModel,self).__init__()\n",
    "        self.model = trained_model\n",
    "        self.mean = torch.tensor(mean,dtype=torch.float32)\n",
    "        self.std = torch.tensor(std,dtype=torch.float32)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        output = torch.unsqueeze(x,0)\n",
    "        output = (output-self.mean)/self.std\n",
    "        output = self.model(output)\n",
    "        return torch.squeeze(self.sigmoid(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 589, 6])\n",
      "torch.Size([1, 589, 1])\n"
     ]
    }
   ],
   "source": [
    "model1 = ConvRecurrentModel(dataset.n).double()\n",
    "sample = torch.tensor(train_set[0]['input']).unsqueeze(0)\n",
    "print(sample.size())\n",
    "print(model1(sample).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 589, 6])\n",
      "torch.Size([1, 589, 1])\n"
     ]
    }
   ],
   "source": [
    "model2 = FullyConvModel().double()\n",
    "sample = torch.tensor(train_set[0]['input']).unsqueeze(0)\n",
    "print(sample.size())\n",
    "print(model2(sample).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([589, 6])\n",
      "torch.Size([589])\n"
     ]
    }
   ],
   "source": [
    "model3 = StandaloneModel(model1,dataset.mean,dataset.std)\n",
    "sample = torch.tensor(train_set[0]['raw_input'])\n",
    "print(sample.size())\n",
    "print(model3(sample).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred,y):\n",
    "    pred_np = pred.squeeze().detach().numpy()\n",
    "    y_np = y.squeeze().detach().numpy()\n",
    "    accuracy = accuracy_score(y_np,pred_np)\n",
    "    precision = precision_score(y_np,pred_np,zero_division=0)\n",
    "    recall = recall_score(y_np,pred_np,zero_division=0)\n",
    "    f1 = f1_score(y_np,pred_np,zero_division=0)\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "def save_model(model,name,acc):\n",
    "    acc = int(10000*acc)/100\n",
    "    f_name = f\"{int(name['MODEL_HIDDEN_SIZE_IN'])}_{int(name['MODEL_HIDDEN_SIZE_OUT'])}_{int(name['MODEL_NUM_LAYERS'])}_{acc}.pt\"\n",
    "    torch.save(model.state_dict(),\"../../models/\"+f_name)\n",
    "    \n",
    "\n",
    "def epoch(loader,optimizer,model,loss,iteration_type='train',gradient_clipping=1.):\n",
    "    if iteration_type == 'train':\n",
    "        MODEL.train()\n",
    "    if iteration_type == 'test':\n",
    "        MODEL.eval()\n",
    "\n",
    "    with ExitStack() as stack:\n",
    "        if iteration_type == 'test':\n",
    "            gs = stack.enter_context(torch.no_grad())\n",
    "        \n",
    "        metrics = {\n",
    "            'loss': 0.,\n",
    "            'accuracy': 0.,\n",
    "            'precision': 0.,\n",
    "            'recall': 0.,\n",
    "            'f1': 0.\n",
    "        }\n",
    "        \n",
    "        n = len(loader)\n",
    "        for sample in loader:\n",
    "            # make predictions\n",
    "            x = sample['input']\n",
    "            y = sample['output'].squeeze()\n",
    "            dist = sample['dist'].squeeze()\n",
    "            augment = np.random.uniform(0.5,1.5) if iteration_type=='train' else 1.\n",
    "            pred = MODEL(augment*x).squeeze()\n",
    "            # compute losses\n",
    "            l = loss(pred,y)\n",
    "            # apply backprop\n",
    "            if iteration_type == 'train':\n",
    "                OPTIMIZER.zero_grad()\n",
    "                l.backward()\n",
    "                '''torch.nn.utils.clip_grad_norm_(\n",
    "                    parameters = model.parameters(),\n",
    "                    max_norm = gradient_clipping\n",
    "                )'''\n",
    "                OPTIMIZER.step()\n",
    "                \n",
    "            acc, prec, rec, f1 = compute_metrics(torch.sigmoid(pred)>0.5,y)\n",
    "            metrics['loss'] += l.item()/n\n",
    "            metrics['accuracy'] += acc/n\n",
    "            metrics['precision'] += prec/n\n",
    "            metrics['recall'] += rec/n\n",
    "            metrics['f1'] += f1/n\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: lmagne (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.1<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">glorious-forest-335</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/lmagne/r-drawing\" target=\"_blank\">https://wandb.ai/lmagne/r-drawing</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/lmagne/r-drawing/runs/ozamzc0l\" target=\"_blank\">https://wandb.ai/lmagne/r-drawing/runs/ozamzc0l</a><br/>\n",
       "                Run data is saved locally in <code>/home/loic/Documents/Prog/Projets/air-drawing/python-stuff/deep-learning/wandb/run-20210909_233341-ozamzc0l</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = {\n",
    "    \"EPOCHS\" : 1000,\n",
    "    \"BATCH_SIZE\" : 1,\n",
    "    \"LEARNING_RATE\" : 3e-4,\n",
    "    \"NUM_WORKERS\" : 2,\n",
    "    \"PIN_MEMORY\" : True,\n",
    "    \"MODEL_HIDDEN_SIZE_IN\" : 32,\n",
    "    \"MODEL_HIDDEN_SIZE_OUT\" : 16,\n",
    "    \"MODEL_NUM_LAYERS\" : 1,\n",
    "    \"WEIGHT_DECAY\" : 0.,\n",
    "    \"SCHEDULER_GAMMA\" : 0.8,\n",
    "    \"SEED\" : 179428,\n",
    "    \"DROPOUT\" : 0.,\n",
    "    \"GRADIENT_CLIPPING\" : None,\n",
    "    \"BIDIRECTIONAL\" : True\n",
    "}\n",
    "log = True\n",
    "if log:\n",
    "    run = wandb.init(project=\"r-drawing\",config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]/home/loic/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 10010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:115.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      " 52%|█████▏    | 521/1000 [1:52:23<1:43:19, 12.94s/it]\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 245, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 411, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-d0af787e130e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0mbest_so_far\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"EPOCHS\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0mtrain_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mOPTIMIZER\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMODEL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLOSS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"GRADIENT_CLIPPING\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0mtest_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mOPTIMIZER\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMODEL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLOSS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-f050132bb4ac>\u001b[0m in \u001b[0;36mepoch\u001b[0;34m(loader, optimizer, model, loss, iteration_type, gradient_clipping)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0miteration_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0mOPTIMIZER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                 \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m                 '''torch.nn.utils.clip_grad_norm_(\n\u001b[1;32m     49\u001b[0m                     \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/wandb/wandb_torch.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(grad)\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_tensor_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_track\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hook_handles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.manual_seed(config[\"SEED\"])\n",
    "np.random.seed(config[\"SEED\"])\n",
    "\n",
    "dataset = DrawingsDS()\n",
    "train_set, test_set = torch.utils.data.random_split(dataset,(50,10))\n",
    "\n",
    "MODEL = ConvRecurrentModel(\n",
    "    input_size = dataset.n,\n",
    "    hidden_size_in = config[\"MODEL_HIDDEN_SIZE_IN\"],\n",
    "    hidden_size_out = config[\"MODEL_HIDDEN_SIZE_OUT\"],\n",
    "    num_layers = config[\"MODEL_NUM_LAYERS\"],\n",
    "    dropout = config[\"DROPOUT\"],\n",
    "    model=torch.nn.LSTM\n",
    ").double()\n",
    "\n",
    "LOSS = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "OPTIMIZER = torch.optim.Adam(\n",
    "    MODEL.parameters(),\n",
    "    lr = config[\"LEARNING_RATE\"],\n",
    "    weight_decay = config[\"WEIGHT_DECAY\"]\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "OPTIMIZER = torch.optim.SGD(\n",
    "    MODEL.parameters(),\n",
    "    lr = config[\"LEARNING_RATE\"],\n",
    "    momentum = 0.9,\n",
    "    nesterov = True\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "SCHEDULER = torch.optim.lr_scheduler.StepLR(\n",
    "    OPTIMIZER,\n",
    "    step_size = 100,\n",
    "    gamma = config[\"SCHEDULER_GAMMA\"]\n",
    ")\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set,\n",
    "    batch_size = config[\"BATCH_SIZE\"],\n",
    "    num_workers = config[\"NUM_WORKERS\"],\n",
    "    pin_memory = config[\"PIN_MEMORY\"],\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_set,\n",
    "    batch_size = config[\"BATCH_SIZE\"],\n",
    "    num_workers = config[\"NUM_WORKERS\"],\n",
    "    pin_memory = config[\"PIN_MEMORY\"],\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "if log:\n",
    "    wandb.watch(MODEL)\n",
    "    \n",
    "best_so_far = 0.\n",
    "for k in tqdm(range(config[\"EPOCHS\"])):\n",
    "    train_metrics = epoch(train_loader,OPTIMIZER,MODEL,LOSS,'train',config[\"GRADIENT_CLIPPING\"])\n",
    "    test_metrics = epoch(test_loader,OPTIMIZER,MODEL,LOSS,'test')\n",
    "    if log:\n",
    "        wandb.log({\n",
    "            \"loss_train\" : train_metrics[\"loss\"],\n",
    "            \"loss_test\" : test_metrics[\"loss\"],\n",
    "            \"accuracy_train\" : train_metrics[\"accuracy\"],\n",
    "            \"accuracy_test\" : test_metrics[\"accuracy\"],\n",
    "            \"precision_train\" : train_metrics[\"precision\"],\n",
    "            \"precision_test\" : test_metrics[\"precision\"],\n",
    "            \"recall_train\" : train_metrics[\"recall\"],\n",
    "            \"recall_test\" : test_metrics[\"recall\"],\n",
    "            \"f1_train\" : train_metrics[\"f1\"],\n",
    "            \"f1_test\" : test_metrics[\"f1\"]\n",
    "        })\n",
    "    if test_metrics['accuracy'] > best_so_far:\n",
    "        save_model(MODEL,config,test_metrics['accuracy'])\n",
    "        best_so_far = test_metrics['accuracy']\n",
    "    SCHEDULER.step()\n",
    "\n",
    "if log:\n",
    "    run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stopQQjax.csv\n",
      "secret.csv\n",
      "balancoire.csv\n",
      "issouent.csv\n",
      "kayak.csv\n",
      "key.csv\n",
      "hat.csv\n",
      "smiley.csv\n",
      "magicien.csv\n",
      "salut.csv\n"
     ]
    }
   ],
   "source": [
    "for k in range(10):\n",
    "    sample = test_set[k]\n",
    "    print(sample['name'])\n",
    "    x = torch.tensor(sample['input']).unsqueeze(0)\n",
    "    pred = (torch.sigmoid(MODEL(x)) > 0.5).detach().numpy()\n",
    "    visualize(sample,pred)\n",
    "    visualize(sample,sample['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safety_check():\n",
    "    MODEL = ConvRecurrentModel(\n",
    "        input_size = dataset.n,\n",
    "        hidden_size_in = 32,\n",
    "        hidden_size_out = 16,\n",
    "        num_layers = 1,\n",
    "        dropout = 0.,\n",
    "        model=torch.nn.LSTM\n",
    "    )\n",
    "    MODEL.load_state_dict(torch.load(f\"../../models/32_16_1_83.85.pt\"))\n",
    "    MODEL.eval()\n",
    "    exportable_model = StandaloneModel(MODEL,dataset.mean,dataset.std)\n",
    "    exportable_model.eval()\n",
    "    sample = test_set[0]\n",
    "    x1 = torch.tensor(sample['input'],dtype=torch.float32).unsqueeze(0)\n",
    "    x2 = torch.tensor(sample['raw_input'],dtype=torch.float32)\n",
    "    y1 = torch.sigmoid(MODEL(x1)).squeeze()\n",
    "    y2 = exportable_model(x2)\n",
    "    assert np.all(np.isclose(y1.detach().numpy(),y2.detach().numpy()))\n",
    "    assert np.all(np.isclose(y2.detach().numpy(),y1.detach().numpy()))\n",
    "safety_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toONNX():\n",
    "    MODEL = ConvRecurrentModel(\n",
    "        input_size = dataset.n,\n",
    "        hidden_size_in = 32,\n",
    "        hidden_size_out = 16,\n",
    "        num_layers = 1,\n",
    "        dropout = 0.,\n",
    "        model=torch.nn.LSTM\n",
    "    )\n",
    "    MODEL.load_state_dict(torch.load(f\"../../models/32_16_1_82.57.pt\"))\n",
    "    MODEL.eval()\n",
    "    exportable_model = StandaloneModel(MODEL,dataset.mean,dataset.std)\n",
    "    exportable_model.eval()\n",
    "    x = torch.randn(500, 6, requires_grad=True,dtype=torch.float)\n",
    "    y = exportable_model(x)\n",
    "    torch.onnx.export(exportable_model,               # model being run\n",
    "                      x,                         # model input (or a tuple for multiple inputs)\n",
    "                      f\"../../models/lstm_1_82_57.onnx\",   # where to save the model (can be a file or file-like object)\n",
    "                      input_names = ['input'],   # the model's input names\n",
    "                      output_names = ['output'], # the model's output names\n",
    "                      dynamic_axes={'input' : {0 : 'seq_len'},    # variable length axes\n",
    "                                    'output' : {0 : 'seq_len'}},\n",
    "                      verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%input : Float(*, 6, strides=[6, 1], requires_grad=1, device=cpu),\n",
      "      %model.before.0.weight : Float(16, 6, 3, strides=[18, 3, 1], requires_grad=1, device=cpu),\n",
      "      %model.before.0.bias : Float(16, strides=[1], requires_grad=1, device=cpu),\n",
      "      %model.before.2.weight : Float(16, 16, 3, strides=[48, 3, 1], requires_grad=1, device=cpu),\n",
      "      %model.before.2.bias : Float(16, strides=[1], requires_grad=1, device=cpu),\n",
      "      %model.before.4.weight : Float(32, 16, 3, strides=[48, 3, 1], requires_grad=1, device=cpu),\n",
      "      %model.before.4.bias : Float(32, strides=[1], requires_grad=1, device=cpu),\n",
      "      %model.after.0.weight : Float(16, 32, 3, strides=[96, 3, 1], requires_grad=1, device=cpu),\n",
      "      %model.after.0.bias : Float(16, strides=[1], requires_grad=1, device=cpu),\n",
      "      %model.after.2.weight : Float(16, 16, 3, strides=[48, 3, 1], requires_grad=1, device=cpu),\n",
      "      %model.after.2.bias : Float(16, strides=[1], requires_grad=1, device=cpu),\n",
      "      %model.after.4.weight : Float(8, 16, 3, strides=[48, 3, 1], requires_grad=1, device=cpu),\n",
      "      %model.after.4.bias : Float(8, strides=[1], requires_grad=1, device=cpu),\n",
      "      %model.fc.bias : Float(1, strides=[1], requires_grad=1, device=cpu),\n",
      "      %114 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
      "      %115 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
      "      %116 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
      "      %117 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
      "      %158 : Float(2, 128, strides=[128, 1], requires_grad=0, device=cpu),\n",
      "      %159 : Float(2, 64, 32, strides=[2048, 32, 1], requires_grad=0, device=cpu),\n",
      "      %160 : Float(2, 64, 16, strides=[1024, 16, 1], requires_grad=0, device=cpu),\n",
      "      %161 : Float(8, 1, strides=[1, 8], requires_grad=0, device=cpu)):\n",
      "  %23 : Float(1, *, 6, strides=[3000, 6, 1], requires_grad=1, device=cpu) = onnx::Unsqueeze[axes=[0]](%input) # <ipython-input-9-2989dca95cab>:14:0\n",
      "  %24 : Float(6, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=-1.2630e-01  1.4131e-01  5.4324e+00  4.9640e-05  1.5444e-02  5.2978e+00 [ CPUFloatType{6} ]]()\n",
      "  %25 : Float(1, *, 6, strides=[3000, 6, 1], requires_grad=1, device=cpu) = onnx::Sub(%23, %24) # <ipython-input-9-2989dca95cab>:15:0\n",
      "  %26 : Float(6, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=  7.5895   6.6007   8.4672   9.1564   7.5864  10.6455 [ CPUFloatType{6} ]]()\n",
      "  %27 : Float(1, *, 6, strides=[3000, 6, 1], requires_grad=1, device=cpu) = onnx::Div(%25, %26) # <ipython-input-9-2989dca95cab>:15:0\n",
      "  %28 : Float(1, 6, *, strides=[3000, 1, 6], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1]](%27) # <ipython-input-8-2898c75afbdd>:38:0\n",
      "  %29 : Float(1, 16, *, strides=[8000, 500, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[3], pads=[1, 1], strides=[1]](%28, %model.before.0.weight, %model.before.0.bias) # /home/loic/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:294:0\n",
      "  %30 : Float(1, 16, *, strides=[8000, 500, 1], requires_grad=1, device=cpu) = onnx::Relu(%29) # /home/loic/.local/lib/python3.8/site-packages/torch/nn/functional.py:1298:0\n",
      "  %31 : Float(1, 16, *, strides=[8000, 500, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[3], pads=[1, 1], strides=[1]](%30, %model.before.2.weight, %model.before.2.bias) # /home/loic/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:294:0\n",
      "  %32 : Float(1, 16, *, strides=[8000, 500, 1], requires_grad=1, device=cpu) = onnx::Relu(%31) # /home/loic/.local/lib/python3.8/site-packages/torch/nn/functional.py:1298:0\n",
      "  %33 : Float(1, 32, *, strides=[16000, 500, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[3], pads=[1, 1], strides=[1]](%32, %model.before.4.weight, %model.before.4.bias) # /home/loic/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:294:0\n",
      "  %34 : Float(*, 1, 32, strides=[1, 16000, 500], requires_grad=1, device=cpu) = onnx::Transpose[perm=[2, 0, 1]](%33) # <ipython-input-8-2898c75afbdd>:42:0\n",
      "  %35 : Long(3, strides=[1], device=cpu) = onnx::Shape(%34)\n",
      "  %36 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
      "  %37 : Long(device=cpu) = onnx::Gather[axis=0](%35, %36) # /home/loic/.local/lib/python3.8/site-packages/torch/nn/modules/rnn.py:658:0\n",
      "  %41 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%37)\n",
      "  %43 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%114, %41, %115)\n",
      "  %44 : Float(*, *, *, strides=[16, 16, 1], requires_grad=0, device=cpu) = onnx::ConstantOfShape[value={0}](%43) # /home/loic/.local/lib/python3.8/site-packages/torch/nn/modules/rnn.py:665:0\n",
      "  %48 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%37)\n",
      "  %50 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%116, %48, %117)\n",
      "  %51 : Float(*, *, *, strides=[16, 16, 1], requires_grad=0, device=cpu) = onnx::ConstantOfShape[value={0}](%50) # /home/loic/.local/lib/python3.8/site-packages/torch/nn/modules/rnn.py:668:0\n",
      "  %52 : Tensor? = prim::Constant()\n",
      "  %96 : Float(*, 2, 1, 16, device=cpu), %97 : Float(2, 1, 16, strides=[16, 16, 1], requires_grad=1, device=cpu), %98 : Float(2, 1, 16, strides=[16, 16, 1], requires_grad=1, device=cpu) = onnx::LSTM[direction=\"bidirectional\", hidden_size=16](%34, %159, %160, %158, %52, %44, %51) # /home/loic/.local/lib/python3.8/site-packages/torch/nn/modules/rnn.py:679:0\n",
      "  %99 : Float(*, 1, 2, 16, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%96)\n",
      "  %100 : Long(3, strides=[1], device=cpu) = onnx::Constant[value= 0  0 -1 [ CPULongType{3} ]]()\n",
      "  %101 : Float(*, 1, 32, strides=[32, 32, 1], requires_grad=1, device=cpu) = onnx::Reshape(%99, %100) # /home/loic/.local/lib/python3.8/site-packages/torch/nn/modules/rnn.py:679:0\n",
      "  %102 : Float(1, 32, *, strides=[32, 1, 32], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 2, 0]](%101) # <ipython-input-8-2898c75afbdd>:46:0\n",
      "  %103 : Float(1, 16, *, strides=[8000, 500, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[3], pads=[1, 1], strides=[1]](%102, %model.after.0.weight, %model.after.0.bias) # /home/loic/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:294:0\n",
      "  %104 : Float(1, 16, *, strides=[8000, 500, 1], requires_grad=1, device=cpu) = onnx::Relu(%103) # /home/loic/.local/lib/python3.8/site-packages/torch/nn/functional.py:1298:0\n",
      "  %105 : Float(1, 16, *, strides=[8000, 500, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[3], pads=[1, 1], strides=[1]](%104, %model.after.2.weight, %model.after.2.bias) # /home/loic/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:294:0\n",
      "  %106 : Float(1, 16, *, strides=[8000, 500, 1], requires_grad=1, device=cpu) = onnx::Relu(%105) # /home/loic/.local/lib/python3.8/site-packages/torch/nn/functional.py:1298:0\n",
      "  %107 : Float(1, 8, *, strides=[4000, 500, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[3], pads=[1, 1], strides=[1]](%106, %model.after.4.weight, %model.after.4.bias) # /home/loic/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:294:0\n",
      "  %108 : Float(1, *, 8, strides=[4000, 1, 500], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1]](%107) # <ipython-input-8-2898c75afbdd>:49:0\n",
      "  %110 : Float(1, *, 1, device=cpu) = onnx::MatMul(%108, %161)\n",
      "  %111 : Float(1, *, 1, strides=[500, 1, 1], requires_grad=1, device=cpu) = onnx::Add(%model.fc.bias, %110) # /home/loic/.local/lib/python3.8/site-packages/torch/nn/functional.py:1847:0\n",
      "  %112 : Float(1, *, 1, strides=[500, 1, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%111) # /home/loic/.local/lib/python3.8/site-packages/torch/nn/modules/activation.py:299:0\n",
      "  %output : Float(500, strides=[1], requires_grad=1, device=cpu) = onnx::Squeeze(%112) # <ipython-input-9-2989dca95cab>:17:0\n",
      "  return (%output)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/loic/.local/lib/python3.8/site-packages/torch/onnx/symbolic_opset9.py:2095: UserWarning: Exporting a model to ONNX with a batch_size other than 1, with a variable length with LSTM can cause an error when running the ONNX model with a different batch size. Make sure to save the model with a batch size of 1, or define the initial states (h0/c0) as inputs of the model. \n",
      "  warnings.warn(\"Exporting a model to ONNX with a batch_size other than 1, \" +\n"
     ]
    }
   ],
   "source": [
    "toONNX()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[\n",
    "    [1,2,3,4,5,6],\n",
    "    [1,2,3,4,5,6],\n",
    "    [1,2,3,4,5,6],\n",
    "    [1,2,3,4,5,6]\n",
    "]])\n",
    "mean = torch.tensor(dataset.mean)\n",
    "std = torch.tensor(dataset.std)\n",
    "print(x.size())\n",
    "print(mean.size())\n",
    "\n",
    "print(mean)\n",
    "print(x[0]-mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
